\documentclass[12pt, titlepage]{article}

\usepackage{placeins} % Add this in the preamble

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

\begin{document}

\title{System Verification and Validation Plan for Uno-Flip 3D} 
\author{
    Team 24, Uno-Flip 3D \\[10pt]
    Mingyang Xu \\ 
    Kevin Ishak \\ 
    Jianhao Wei \\ 
    Zheng Bang Liang \\ 
    Zain-Alabedeen Garada
}
\date{November 3, 2024}

\maketitle

\pagenumbering{roman}

\section*{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule
{\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
2024.Oct.29 & 1.0 & Created a shared file\\
2024.Oct.30 & 1.1 & Wrote section 1-2\\
2024.Oct.31 & 1.2 & Wrote section 3 and modified sections 1 and 2\\
2024.Nov.1 & 1.3 & Wrote content for section 4 and reflection\\
\bottomrule
\end{tabularx}

\newpage

\tableofcontents
\newpage

\listoftables
\begin{table}[h!]
\centering
\begin{tabular}{|c|l|c|}
\hline
\textbf{Table Number} & \textbf{Title} & \textbf{Page Number} \\ \hline
1 & Summary of tables list & 2 \\ \hline
2 & Team member's responsibility & 7 \\ \hline
3 & Traceability table I & 33 \\ \hline
4 & Traceability table II & 34 \\ \hline
\end{tabular}
\caption{Summary of tables list}
\end{table}

\newpage

\section{Symbols, Abbreviations, and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{Symbol} & \textbf{Description}\\
  \midrule 
  SRS & System Requirements Specification\\
  PSAG & Problem Statement and Goals\\
  \bottomrule
\end{tabular}\\

\newpage

\pagenumbering{arabic}

\section{General Information}

\subsection{Summary}
The software being tested is an UNO Flip game application, developed to provide an engaging, digital version of the popular card game with additional features for enhanced user experience. The game includes functionalities such as switching between two sides of the cards (light and dark), maintaining score, tracking player moves, and handling various card effects. This software aims to capture the essence of the physical game while offering interactive elements that make it enjoyable on a digital platform.

\subsection{Objectives}
The primary objective of the Verification and Validation (V\&V) plan is to build confidence in the correctness and stability of the game software, ensuring a smooth user experience with minimal bugs. Key objectives include:

\begin{itemize}
    \item \textbf{Verifying functionality}: Testing to ensure that core game mechanics, such as card flipping, turn-taking, and scoring, work as expected.
    \item \textbf{Ensuring performance}: Assessing the software’s responsiveness and ensuring minimal lag or delay in gameplay.
    \item \textbf{Evaluating user experience}: Conducting usability tests to confirm that the interface is intuitive and enhances engagement.
\end{itemize}

Out of scope:

\begin{itemize}
    \item \textbf{Accessibility testing}: Due to limited resources, we are not performing detailed accessibility testing. Our focus is on verifying core gameplay features.
    \item \textbf{Advanced AI opponent testing}: Since the game primarily targets player-vs-player mode, sophisticated AI functionality is not within our current scope.
\end{itemize}

\subsection{Challenge Level and Extras}
The challenge level for this project is general, as agreed with the course instructor. This level reflects the game’s moderate complexity, focusing on implementing and testing the main gameplay mechanics without advanced AI or complex networking.

Extras included in the project:
\begin{itemize}
    \item Usability testing to ensure the game provides an enjoyable user experience.
    \item User documentation to guide players on gameplay rules and controls.
    \item Design Thinking techniques applied during the design phase to create an engaging interface.
\end{itemize}

\subsection{Relevant Documentation}
\begin{itemize}
    \item \textbf{SRS}: This document outlines the game's functional and non-functional requirements, providing the foundation for the test cases designed in this V\&V plan. Available at: \url{https://github.com/zgarada/UNO-Flip-3D/blob/main/docs/SRS/SRS.pdf}
    \item \textbf{PSAG}: Defines our problem statement and goals. Available at: \url{https://github.com/zgarada/UNO-Flip-3D/blob/main/docs/ProblemStatementAndGoals/ProblemStatement.pdf}
\end{itemize}

\section{Plan}
This section provides an overview of the planned verification and validation (V\&V) activities for our project. The plan outlines the roles and responsibilities of the team members, strategies for verifying the SRS, design, and implementation, as well as the testing approaches for both functional and non-functional requirements. By following this plan, we aim to ensure that our software meets all specified requirements and maintains high reliability, usability, and performance standards.


\subsection{Verification and Validation Team}

\begin{table}[H]
\centering
\small % Reduce the font size for the table to make it fit on one page
\begin{tabularx}{\textwidth}{|l|l|X|}
\hline
\textbf{Team Member} & \textbf{Role} & \textbf{Responsibilities} \\ \hline
Mingyang Xu & Lead Validator & Oversees the V\&V process, ensures adherence to the plan, and coordinates team efforts. \\ \hline
Jianhao Wei & SRS and Design Reviewer & Reviews the SRS and design documents, providing feedback on requirement clarity and feasibility. \\ \hline
Zheng Bang Liang & Code Verification Specialist & Implements unit and integration tests, and conducts code inspections and reviews. \\ \hline
Zain-Alabedeen Garada & System Test Engineer & Designs and executes system tests, covering functional and non-functional requirements, and reports outcomes. \\ \hline
Kevin Ishak & System Test Engineer & Assists in designing and executing system tests, and reporting on test coverage and outcomes. \\ \hline
\end{tabularx}
\caption{Team member's responsibility}
\end{table}

\FloatBarrier % Force the table to stay within this section


\subsection{SRS Verification Plan}

\begin{enumerate}
    \item \textbf{Review Process}: The SRS document will undergo a formal peer review with the primary reviewer being Jianhao Wei, supported by the external reviewer (supervisor). This review will assess requirement clarity, completeness, and feasibility.
    \item \textbf{Meeting with Supervisor}: A dedicated meeting will be arranged with our supervisor to go over the SRS document. During this session, we will present the requirements, ask targeted questions to clarify expectations, and gather any suggestions for improvement.
    \item \textbf{SRS Checklist}: We will develop a detailed SRS checklist to ensure that all requirements are specific, measurable, achievable, relevant, and time-bound (SMART). This checklist will cover critical aspects like requirement consistency, clarity, traceability, and testability.
    \item \textbf{Use of Issue Tracker}: All identified issues during the SRS review will be logged in our project’s GitHub issue tracker, including detailed descriptions and suggestions for resolution. This facilitates transparent tracking of revisions and provides a record of feedback incorporated into the final SRS document.
    \item \textbf{Task-Based Inspection}: We will perform a task-based inspection where each team member reviews a specific portion of the SRS related to their responsibility, ensuring testability and alignment with specified functional requirements.
    \item \textbf{Ad Hoc Feedback}: Additional feedback from classmates and peers experienced in software design will be sought to further improve the SRS.
\end{enumerate}

\subsection{Design Verification Plan}
To verify the design of the project, we will implement a structured review process that involves peer feedback, checklists, and verification through multiple review stages:

\begin{enumerate}
    \item \textbf{Peer Reviews}: The design document will undergo reviews by team members and classmates, focusing on design consistency, feasibility, and alignment with the SRS.
    \item \textbf{Checklist-Based Verification}: A checklist specific to design verification will be created to ensure modularity, reusability, scalability, and maintainability.
    \item \textbf{Review Meeting with Supervisor}: A design review session will be scheduled with our supervisor, where the team will present the high-level architecture and major components.
    \item \textbf{Issue Tracker}: Any issues or suggested improvements identified will be documented in the GitHub issue tracker.
\end{enumerate}

\subsection{Verification and Validation Plan Verification Plan}
The Verification and Validation (V\&V) Plan itself is also an artifact that must be verified to ensure it comprehensively addresses all aspects of the V\&V process. We will use the following approaches:

\begin{enumerate}
    \item \textbf{Peer Review and Checklist}: The V\&V plan will be reviewed by team members, focusing on clarity, completeness, and feasibility.
    \item \textbf{Mutation Testing}: We will conduct mutation testing on select test cases in the V\&V plan to verify its effectiveness.
    \item \textbf{Classmate Feedback}: Feedback from classmates will be solicited to identify any gaps or areas for improvement.
    \item \textbf{Supervisor Review}: The supervisor will review the V\&V plan as an external reviewer, providing insights on the feasibility and thoroughness of our processes.
    \item \textbf{Checklist Creation}: A specific checklist for the V\&V Plan verification will be developed, covering elements like system tests, unit tests, and traceability.
\end{enumerate}

\subsection{Implementation Verification Plan}
The Implementation Verification Plan outlines the strategies and methods to verify the correctness and reliability of the software during the implementation phase.

\begin{enumerate}
    \item \textbf{Unit Testing}: Each module and function will be verified through detailed unit tests, including edge cases. The tests will be automated and continuously run.
    \item \textbf{Static Code Analysis}: Static analyzers will be used to inspect the source code for bugs, coding standards, and areas of improvement.
    \item \textbf{Code Walkthroughs and Inspections}: Regular code walkthroughs will be conducted among team members to verify readability and adherence to design specifications.
    \item \textbf{Final Class Presentation as Code Walkthrough}: The final presentation in CAS 741 will serve as a formal code walkthrough, allowing feedback from peers and the instructor.
\end{enumerate}

\subsection{Automated Testing and Verification Tools}
We will utilize a suite of automated tools for testing and verification to ensure efficiency and consistency across the project:

\begin{itemize}
    \item \textbf{Unit Testing Framework}: A framework will automate unit tests for individual components.
    \item \textbf{Code Coverage Tools}: Tools will be used to track code coverage by tests and identify areas that need additional testing.
    \item \textbf{Continuous Integration (CI)}: A CI tool will automate testing, ensuring that new changes do not introduce regressions.
    \item \textbf{Static Analyzer}: Static analyzers will check for coding standard violations, potential bugs, and security vulnerabilities.
    \item \textbf{Linters}: Linters will enforce code formatting and style standards.
\end{itemize}

\subsection{Software Validation Plan}
The Software Validation Plan is designed to validate that the software meets the user requirements and operates as intended within the real-world context.

\begin{enumerate}
    \item \textbf{User Review Sessions}: Regular review sessions with stakeholders or users to verify the software’s usability and alignment with user experience expectations.
    \item \textbf{Rev 0 Demo for External Supervisor}: A demonstration will showcase the initial implementation of key features to gather supervisor feedback.
    \item \textbf{User Testing}: In the absence of an external supervisor, user testing will serve to validate usability, functionality, and user satisfaction.
    \item \textbf{Task-Based Inspection}: Inspections will confirm that user requirements are effectively captured in the requirements document.
    \item \textbf{Reference to SRS Verification}: The validation process will reference the SRS verification to ensure alignment with all documented requirements.
\end{enumerate}

\newpage


\section{System Tests}

This section outlines the testing procedures designed to verify that the system meets its functional and non-functional requirements. The tests will cover various areas to ensure comprehensive validation of the system’s functionality, performance, and usability. Each area will address specific requirements and reference the Software Requirements Specification (SRS) for detailed test criteria.

\subsection{Tests for Functional Requirements}

\subsubsection{Area of Testing: Authentication}

The Authentication tests are critical to ensure that only registered users can access the game and that the security of user credentials is maintained. This area includes tests for standard login operations as well as edge cases, such as handling incorrect credentials and verifying session security. The tests are derived from the SRS, specifically the sections covering security and access control requirements.

\begin{enumerate}
    \item \textbf{Test ID: AR1-Test01}
        \begin{itemize}
            \item Control: Manual
            \item State: No precondition required
            \item Input: Log in using valid username and password for an existing account.
            \item Output: User successfully logs in and accesses the multiplayer mode.
            \item Test Case Derivation: Verifies that the authentication system correctly identifies and validates existing users.
            \item Test Steps:
                \begin{enumerate}
                    \item Open the login screen.
                    \item Enter a valid username and password.
                    \item Click the login button.
                \end{enumerate}
            \item Validation: Confirm that the user is directed to the game’s main screen and can access the multiplayer mode.
        \end{itemize}

    \item \textbf{Test ID: AR2-Test02}
        \begin{itemize}
            \item Control: Manual
            \item State: User is logged in and has a profile.
            \item Input: Access the user profile page.
            \item Output: User sees game statistics and preferences.
            \item Test Case Derivation: Verifies that the profile page correctly displays user-specific data.
            \item Test Steps:
                \begin{enumerate}
                    \item Log in and access the main screen.
                    \item Click the "Profile" button.
                \end{enumerate}
            \item Validation: Confirm that the displayed game statistics (e.g., win rate, preferences) match the user’s records.
        \end{itemize}
\end{enumerate}

\subsubsection{Area of Testing: Game Setup}

The Game Setup area is essential for validating the creation and configuration of game rooms, as it directly impacts the player experience. Tests in this area verify that game rooms can be created with the specified rules, difficulty levels, and invite options. Reference to the SRS is made to ensure alignment with the functional requirements related to room creation, rule selection, and multiplayer setup.

\begin{enumerate}
    \item \textbf{Test ID: GSR1-Test01}
        \begin{itemize}
            \item Control: Manual
            \item State: No precondition required
            \item Input: User clicks "Create Room" button.
            \item Output: A new game room is created with options to invite friends.
            \item Test Case Derivation: Verifies that the game room creation functionality works as expected.
            \item Test Steps:
                \begin{enumerate}
                    \item On the main screen, click "Create Room."
                    \item Check if the invite option is displayed.
                \end{enumerate}
            \item Validation: Confirm that a new game room is created and the user can invite other players.
        \end{itemize}
\end{enumerate}


\subsubsection{Area of Testing: Turn Management}

The Turn Management tests verify the correct sequencing of player turns and handling of turn-based actions such as the effects of special cards. This is crucial for ensuring fair gameplay and adherence to game rules as specified in the SRS.

\begin{enumerate}
    \item \textbf{Test ID: TMR1-Test01}
        \begin{itemize}
            \item Control: Automatic
            \item State: Game is in progress with multiple players.
            \item Input: System manages player turns sequentially.
            \item Output: Player turns are synchronized across all devices.
            \item Test Case Derivation: Ensures real-time synchronization of turns in multiplayer mode.
            \item Test Steps:
                \begin{enumerate}
                    \item Start a multiplayer game.
                    \item Observe the turn sequence across all players' screens.
                \end{enumerate}
            \item Validation: Confirm that the current turn is accurately displayed on each player's device.
        \end{itemize}

    \item \textbf{Test ID: TMR1-Test02}
        \begin{itemize}
            \item Control: Automatic
            \item State: A "Skip" card is played.
            \item Input: System processes the "Skip" card.
            \item Output: The next player’s turn is skipped.
            \item Test Case Derivation: Validates the functionality of the "Skip" card in affecting the turn sequence.
            \item Test Steps:
                \begin{enumerate}
                    \item Play a "Skip" card during the game.
                    \item Confirm that the next player’s turn is skipped.
                \end{enumerate}
            \item Validation: Verify that the game correctly skips the next player’s turn after the card is played.
        \end{itemize}

    \item \textbf{Test ID: TMR1-Test03}
        \begin{itemize}
            \item Control: Automatic
            \item State: A "Reverse" card is played.
            \item Input: System processes the "Reverse" card.
            \item Output: The turn order is reversed.
            \item Test Case Derivation: Ensures the functionality of the "Reverse" card in altering the turn direction.
            \item Test Steps:
                \begin{enumerate}
                    \item Play a "Reverse" card during the game.
                    \item Confirm that the turn order changes direction.
                \end{enumerate}
            \item Validation: Verify that the turn direction is reversed following the play of the "Reverse" card.
        \end{itemize}
\end{enumerate}

\subsubsection{Area of Testing: Card Effects (4.1.4)}

The Card Effects tests verify that the special effects of various cards (such as Draw, Skip, and Reverse) work as expected within the game rules. These tests ensure that each card’s effect is correctly applied to the game state and impacts player actions as intended.

\begin{enumerate}
    \item \textbf{Test ID: CE1-Test01}
        \begin{itemize}
            \item Control: Automatic
            \item Initial State: Game in progress with multiple players.
            \item Input: A player plays a "Draw Two" card.
            \item Output: The next player is required to draw two cards.
            \item Test Case Derivation: Verifies that the "Draw Two" card correctly enforces the drawing of two cards by the next player.
            \item Test Steps:
                \begin{enumerate}
                    \item Player 1 plays a "Draw Two" card.
                    \item Observe the next player’s (Player 2’s) turn.
                    \item Verify that Player 2 is forced to draw two cards and then the turn passes.
                \end{enumerate}
            \item Validation: Confirm that the next player draws two cards and the turn sequence proceeds as expected.
        \end{itemize}

    \item \textbf{Test ID: CE1-Test02}
        \begin{itemize}
            \item Control: Automatic
            \item Initial State: Game in progress with multiple players.
            \item Input: A player plays a "Draw Four" Wild card.
            \item Output: The next player is required to draw four cards, and the player playing the card selects a color.
            \item Test Case Derivation: Verifies that the "Draw Four" card correctly enforces the drawing of four cards and allows color selection.
            \item Test Steps:
                \begin{enumerate}
                    \item Player 1 plays a "Draw Four" Wild card.
                    \item Player 1 selects a new color.
                    \item Observe the next player’s (Player 2’s) turn.
                    \item Verify that Player 2 is forced to draw four cards and the color is changed to the selected color.
                \end{enumerate}
            \item Validation: Confirm that the next player draws four cards and that the color is set to the one selected by Player 1.
        \end{itemize}

    \item \textbf{Test ID: CE1-Test03}
        \begin{itemize}
            \item Control: Automatic
            \item Initial State: Game in progress.
            \item Input: A player plays a "Wild" card and selects a new color.
            \item Output: The color changes to the one selected by the player.
            \item Test Case Derivation: Verifies that the "Wild" card allows the player to change the color as intended.
            \item Test Steps:
                \begin{enumerate}
                    \item Player 1 plays a "Wild" card.
                    \item Player 1 selects a new color.
                    \item Confirm that the selected color is applied as the new play color.
                \end{enumerate}
            \item Validation: Verify that the game continues with the color chosen by the player who played the "Wild" card.
        \end{itemize}
\end{enumerate}

\subsubsection{Area of Testing: Game Over Conditions (4.1.5)}

The Game Over Condition tests verify that the game correctly identifies when a player has won or when the game ends under specific conditions. These tests ensure proper detection of a winning condition and proper handling of game termination.

\begin{enumerate}
    \item \textbf{Test ID: GOC1-Test01}
        \begin{itemize}
            \item Control: Automatic
            \item Initial State: Game is in progress.
            \item Input: A player plays their last card.
            \item Output: The game identifies the player as the winner and ends.
            \item Test Case Derivation: Ensures that the game properly detects when a player has no more cards left and triggers the win condition.
            \item Test Steps:
                \begin{enumerate}
                    \item Player 1 plays their last card.
                    \item Observe whether the game identifies Player 1 as the winner.
                    \item Confirm that the game ends and displays a victory message for Player 1.
                \end{enumerate}
            \item Validation: Verify that the game correctly identifies the player with no cards left as the winner and ends.
        \end{itemize}

    \item \textbf{Test ID: GOC1-Test02}
        \begin{itemize}
            \item Control: Automatic
            \item Initial State: Game is in progress with multiple players.
            \item Input: All players except one have left the game.
            \item Output: The remaining player is declared the winner, and the game ends.
            \item Test Case Derivation: Confirms that the game ends automatically when only one player remains, declaring them the winner.
            \item Test Steps:
                \begin{enumerate}
                    \item Start a multiplayer game.
                    \item All players except one leave the game.
                    \item Confirm that the game ends and declares the remaining player as the winner.
                \end{enumerate}
            \item Validation: Verify that the game ends and displays a victory message for the remaining player.
        \end{itemize}
\end{enumerate}

\subsubsection{Area of Testing: Scoring System (4.1.6)}

The Scoring System tests ensure that points are calculated and awarded correctly based on the cards remaining in each player’s hand when the game ends. This area includes tests for verifying score calculation accuracy and ranking players based on their scores.

\begin{enumerate}
    \item \textbf{Test ID: SS1-Test01}
        \begin{itemize}
            \item Control: Automatic
            \item Initial State: Game has just ended.
            \item Input: The system calculates the final scores based on remaining cards.
            \item Output: Players are ranked according to their scores, with points accurately reflecting card values.
            \item Test Case Derivation: Ensures that the scoring system accurately calculates points and ranks players accordingly.
            \item Test Steps:
                \begin{enumerate}
                    \item End a game with various cards remaining in each player’s hand.
                    \item Verify that the system calculates points for each player based on the values of the remaining cards.
                    \item Confirm that players are ranked in descending order of scores.
                \end{enumerate}
            \item Validation: Confirm that the scoring is accurate and players are ranked correctly based on their scores.
        \end{itemize}
\end{enumerate}

\subsubsection{Area of Testing: Multiplayer Synchronization (4.1.7)}

The Multiplayer Synchronization tests verify that all players in a game room experience real-time updates and that actions taken by one player are correctly reflected for all other players. This is critical for ensuring a consistent multiplayer experience.

\begin{enumerate}
    \item \textbf{Test ID: MS1-Test01}
        \begin{itemize}
            \item Control: Automatic
            \item Initial State: Game is in progress with multiple players in a single room.
            \item Input: A player plays a card.
            \item Output: The card play is immediately visible to all other players in the game.
            \item Test Case Derivation: Ensures that player actions are synchronized across all devices in real time.
            \item Test Steps:
                \begin{enumerate}
                    \item Player 1 plays a card.
                    \item Observe all other players’ screens to confirm that the card play is visible instantly.
                \end{enumerate}
            \item Validation: Verify that the card play is synchronized across all players' screens with minimal delay.
        \end{itemize}

    \item \textbf{Test ID: MS1-Test02}
        \begin{itemize}
            \item Control: Automatic
            \item Initial State: Game is in progress with multiple players in a single room.
            \item Input: A player disconnects from the game.
            \item Output: The other players are notified of the disconnection, and the game state is adjusted if necessary.
            \item Test Case Derivation: Ensures that player disconnections are properly handled and that other players are informed.
            \item Test Steps:
                \begin{enumerate}
                    \item Player 1 disconnects from the game.
                    \item Confirm that the remaining players receive a notification about Player 1’s disconnection.
                    \item Verify that the game continues or pauses based on the game’s disconnection policy.
                \end{enumerate}
            \item Validation: Confirm that the disconnection is handled smoothly, with other players notified and the game state updated.
        \end{itemize}
\end{enumerate}

\subsection{Tests for Nonfunctional Requirements (4.2)}

The tests for nonfunctional requirements ensure that the game meets standards for performance, usability, and appearance as specified in the SRS. These tests do not focus on specific functional behavior but rather on the overall quality of the system’s user experience and performance metrics.

\subsubsection{Appearance Requirements (4.2.1)}

These tests verify that the user interface is visually appealing and adheres to modern design standards, as specified in the SRS.

\begin{enumerate}
    \item \textbf{Test ID: AR1-Test01}
        \begin{itemize}
            \item Type: Manual, Visual Inspection
            \item Initial State: Game interface loaded on various screens.
            \item Input: User navigates through different game screens (main menu, gameplay screen, profile, etc.).
            \item Output: All screens have a modern, visually appealing design.
            \item Test Case Derivation: Ensures the game adheres to aesthetic standards specified in the SRS.
            \item Validation: Tester inspects each screen for visual appeal, ensuring consistency in design, color scheme, and layout.
        \end{itemize}
\end{enumerate}

\subsubsection{Speed and Latency Requirements (4.2.2)}

These tests ensure that the game meets response time standards for user actions, providing a smooth and responsive gameplay experience.

\begin{enumerate}
    \item \textbf{Test ID: SALR1-Test01}
        \begin{itemize}
            \item Type: Functional, Dynamic
            \item Initial State: Game is running in multiplayer mode.
            \item Input: Measure the response time between player actions (e.g., playing a card) and system reactions.
            \item Output: Average response time is within 50 milliseconds.
            \item Test Case Derivation: Ensures that the game meets latency standards for a responsive user experience.
            \item Validation: Tester measures response times using a tool to ensure interactions are processed within the acceptable threshold.
        \end{itemize}

    \item \textbf{Test ID: SALR1-Test02}
        \begin{itemize}
            \item Type: Performance Test, Dynamic
            \item Initial State: Game is running with maximum number of players.
            \item Input: Measure latency under high network traffic conditions.
            \item Output: Game maintains response times below 100 milliseconds despite network load.
            \item Test Case Derivation: Verifies that the game can handle network congestion without excessive delays.
            \item Validation: Tester simulates high network traffic and measures latency to ensure the game remains responsive.
        \end{itemize}
\end{enumerate}

\subsubsection{Usability Requirements (4.2.3)}

These tests confirm that the user interface is intuitive and easy to navigate, ensuring a positive experience for players.

\begin{enumerate}
    \item \textbf{Test ID: UR1-Test01}
        \begin{itemize}
            \item Type: Usability Test, Manual
            \item Initial State: User is unfamiliar with the game interface.
            \item Input: Observe a new user attempting to navigate through the main menu and start a game.
            \item Output: User is able to start a game without assistance or confusion.
            \item Test Case Derivation: Ensures that the main menu and navigation are intuitive for new users.
            \item Validation: Tester observes and records any difficulties or questions from the new user to identify areas for improvement.
        \end{itemize}

    \item \textbf{Test ID: UR1-Test02}
        \begin{itemize}
            \item Type: Usability Test, Manual
            \item Initial State: User is in a game session.
            \item Input: Observe user interactions with game controls (e.g., drawing cards, playing cards, pausing game).
            \item Output: User interacts with controls easily and without hesitation.
            \item Test Case Derivation: Ensures that in-game controls are intuitive and easy to use.
            \item Validation: Tester records any confusion or hesitation observed in the user’s interactions.
        \end{itemize}
\end{enumerate}

\subsubsection{Reliability Requirements (4.2.4)}

These tests confirm the stability and reliability of the game, ensuring that it can handle prolonged usage without crashes or data loss.

\begin{enumerate}
    \item \textbf{Test ID: RR1-Test01}
        \begin{itemize}
            \item Type: Reliability Test, Manual
            \item Initial State: Game has been running for an extended period (e.g., 2 hours).
            \item Input: Observe game performance over time.
            \item Output: Game remains stable without crashes or significant lag.
            \item Test Case Derivation: Ensures the system can handle prolonged use.
            \item Validation: Tester records any crashes, freezes, or performance degradation.
        \end{itemize}
\end{enumerate}

\subsubsection{Availability Requirements (4.2.5)}

These tests verify that the game is available for access as required, particularly in multiplayer mode, ensuring minimal downtime.

\begin{enumerate}
    \item \textbf{Test ID: AV1-Test01}
        \begin{itemize}
            \item Type: Availability Test, Automated
            \item Initial State: Game server is running.
            \item Input: Attempt to access the game at different times.
            \item Output: Game is accessible with no more than 5 minutes of downtime within a 24-hour period.
            \item Test Case Derivation: Ensures the game server meets availability standards.
            \item Validation: Automated system checks for server uptime and logs any downtime occurrences.
        \end{itemize}
\end{enumerate}

\subsubsection{Security Requirements (4.2.6)}

These tests ensure that user data is secure and that unauthorized access is prevented.

\begin{enumerate}
    \item \textbf{Test ID: SR1-Test01}
        \begin{itemize}
            \item Type: Security Test, Manual
            \item Initial State: User is logged in.
            \item Input: Attempt to access another user’s profile or data without permission.
            \item Output: Access is denied, and an error message is displayed.
            \item Test Case Derivation: Ensures unauthorized access is prevented.
            \item Validation: Verify that access control mechanisms block unauthorized access attempts.
        \end{itemize}
\end{enumerate}

\subsubsection{Maintainability Requirements (4.2.7)}

These tests verify that the code is maintainable and can be updated or debugged with ease.

\begin{enumerate}
    \item \textbf{Test ID: MR1-Test01}
        \begin{itemize}
            \item Type: Maintainability Test, Code Review
            \item Initial State: Access to code repository.
            \item Input: Review code for modularity and documentation.
            \item Output: Code is well-documented and modular, facilitating maintenance.
            \item Test Case Derivation: Ensures that code is easy to maintain and understand.
            \item Validation: Code reviewer verifies adherence to coding standards and documentation completeness.
        \end{itemize}
\end{enumerate}

\subsubsection{Portability Requirements (4.2.8)}

These tests ensure that the game operates correctly across different platforms and devices.

\begin{enumerate}
    \item \textbf{Test ID: PR1-Test01}
        \begin{itemize}
            \item Type: Portability Test, Manual
            \item Initial State: Game is available on multiple platforms (e.g., Windows, macOS, mobile).
            \item Input: Run the game on different devices and platforms.
            \item Output: Game functions correctly on each platform without compatibility issues.
            \item Test Case Derivation: Ensures cross-platform compatibility.
            \item Validation: Tester verifies that the game behaves consistently across platforms.
        \end{itemize}
\end{enumerate}

\subsubsection{Scalability Requirements (4.2.9)}

These tests confirm that the game can handle increasing numbers of players without performance degradation.

\begin{enumerate}
    \item \textbf{Test ID: SCR1-Test01}
        \begin{itemize}
            \item Type: Scalability Test, Automated
            \item Initial State: Game server running with low player load.
            \item Input: Gradually increase the number of players.
            \item Output: Server maintains performance as player count increases up to the maximum supported level.
            \item Test Case Derivation: Ensures that the game scales with user demand.
            \item Validation: Automated test scripts measure server performance as load increases.
        \end{itemize}
\end{enumerate}

\subsubsection{Performance Requirements (4.2.10)}

These tests assess the game’s performance under typical and peak conditions, ensuring that response times remain within acceptable limits.

\begin{enumerate}
    \item \textbf{Test ID: PRF1-Test01}
        \begin{itemize}
            \item Type: Performance Test, Manual
            \item Initial State: Game running under typical conditions.
            \item Input: Measure response time and frame rate.
            \item Output: Response time is below 100ms, and frame rate is consistent.
            \item Test Case Derivation: Ensures acceptable performance metrics are maintained.
            \item Validation: Tester records performance metrics during gameplay.
        \end{itemize}
\end{enumerate}

\subsubsection{Accessibility Requirements (4.2.11)}

These tests verify that the game is accessible to users with disabilities and adheres to relevant accessibility standards.

\begin{enumerate}
    \item \textbf{Test ID: ACC1-Test01}
        \begin{itemize}
            \item Type: Accessibility Test, Manual
            \item Initial State: Game interface loaded with accessibility features enabled.
            \item Input: Test interface with screen reader and keyboard-only navigation.
            \item Output: Interface is fully navigable using accessibility tools.
            \item Test Case Derivation: Ensures that the game is accessible to users with visual and motor impairments.
            \item Validation: Tester uses screen reader and keyboard to verify accessibility features.
        \end{itemize}
\end{enumerate}

\subsubsection{Compatibility Requirements (4.2.12)}

These tests ensure that the game is compatible with a variety of operating systems, browsers, and hardware configurations.

\begin{enumerate}
    \item \textbf{Test ID: COMP1-Test01}
        \begin{itemize}
            \item Type: Compatibility Test, Manual
            \item Initial State: Game available on multiple operating systems and browsers.
            \item Input: Run the game on different OS (Windows, macOS) and browsers (Chrome, Firefox).
            \item Output: Game functions as expected on each configuration.
            \item Test Case Derivation: Ensures compatibility across various system configurations.
            \item Validation: Tester verifies game functionality on each platform and browser.
        \end{itemize}
\end{enumerate}

\subsection{Traceability Between Test Cases and Requirements (4.3)}

The following tables illustrate the traceability between test cases and the requirements specified in the Software Requirements Specification (SRS). This mapping ensures that all requirements have been addressed by at least one test case, providing comprehensive coverage and validating that the system meets all specified needs.

\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{|l|X|X|}
\hline
\textbf{Requirement ID} & \textbf{Requirement Description} & \textbf{Test Case ID(s)} \\ \hline
FR1: User Authentication & The system must authenticate users to ensure that only registered players can access the game. & AR1-Test01, AR1-Test02, AR1-Test03, AR1-Test04 \\ \hline
FR2: Game Room Creation & The system must allow users to create a game room and invite other players to join. & GSR1-Test01, GSR1-Test02, GSR1-Test03 \\ \hline
FR3: Turn Management & The game must manage player turns accurately, ensuring each player gets their turn in sequence. & TMR1-Test01, TMR1-Test02, TMR1-Test03 \\ \hline
FR4: Card Effects & Special cards (e.g., Draw Two, Reverse) must have their intended effects on gameplay. & CE1-Test01, CE1-Test02, CE1-Test03 \\ \hline
FR5: Game Over Conditions & The game must identify when a player has won and end the game accordingly. & GOC1-Test01, GOC1-Test02 \\ \hline
\end{tabularx}
\caption{Traceability Table between Requirements, Descriptions, and Test Cases (Part 1)}
\end{table}

\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{|l|X|X|}
\hline
\textbf{Requirement ID} & \textbf{Requirement Description} & \textbf{Test Case ID(s)} \\ \hline
FR6: Scoring System & The system must calculate scores based on the cards remaining in players’ hands at the end of the game. & SS1-Test01 \\ \hline
NFR1: Appearance & The game interface must have a modern and visually appealing design. & AR1-Test01 \\ \hline
NFR2: Speed and Latency & The game must respond to user actions within a specified latency threshold to ensure a smooth experience. & SALR1-Test01, SALR1-Test02 \\ \hline
NFR3: Usability & The interface must be intuitive and easy for users to navigate and interact with. & UR1-Test01, UR1-Test02 \\ \hline
NFR4: Reliability & The game must maintain stability over extended use without crashes or data loss. & RR1-Test01 \\ \hline
\end{tabularx}
\caption{Traceability Table between Requirements, Descriptions, and Test Cases (Part 2)}
\end{table}

\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{|l|X|X|}
\hline
\textbf{Requirement ID} & \textbf{Requirement Description} & \textbf{Test Case ID(s)} \\ \hline
NFR5: Availability & The game server must be available with minimal downtime, ensuring players can access the game as required. & AV1-Test01 \\ \hline
NFR6: Security & The system must protect user data and prevent unauthorized access. & SR1-Test01 \\ \hline
NFR7: Maintainability & The codebase must be well-structured and documented, allowing for easy updates and debugging. & MR1-Test01 \\ \hline
NFR8: Portability & The game must be compatible with multiple platforms (e.g., Windows, macOS, mobile). & PR1-Test01 \\ \hline
NFR9: Scalability & The system must handle increasing numbers of players without significant performance degradation. & SCR1-Test01 \\ \hline
\end{tabularx}
\caption{Traceability Table between Requirements, Descriptions, and Test Cases (Part 3)}
\end{table}

\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{|l|X|X|}
\hline
\textbf{Requirement ID} & \textbf{Requirement Description} & \textbf{Test Case ID(s)} \\ \hline
NFR10: Performance & The game must maintain acceptable performance metrics under typical and peak conditions. & PRF1-Test01 \\ \hline
NFR11: Accessibility & The game must be accessible to users with disabilities, adhering to relevant accessibility standards. & ACC1-Test01 \\ \hline
NFR12: Compatibility & The game must function correctly across various operating systems, browsers, and hardware configurations. & COMP1-Test01 \\ \hline
\end{tabularx}
\caption{Traceability Table between Requirements, Descriptions, and Test Cases (Part 4)}
\end{table}

\newpage

\section{References}
\begin{enumerate}
    \item Uno Flip Online Game, "Play Uno Flip Online," [Online]. Available: \url{https://unoonlinegame.io/uno-flip-online}. Accessed: Nov. 1, 2024.

    \item Software Testing Help, "Test Plan Sample – Software Testing and Quality Assurance Templates," [Online]. Available: \url{https://www.softwaretestinghelp.com/test-plan-sample-softwaretesting-and-quality-assurance-templates/}. Accessed: Nov. 1, 2024.

    \item McMaster University, "Integrated Stroke Test Plan," GitLab, [Online]. Available: \url{https://gitlab.cas.mcmaster.ca/courses/capstone/-/blob/main/SamplesOfStudentWork/VnVPlan/IntegratedStrokeTestPlan.pdf}. Accessed: Nov. 1, 2024.
\end{enumerate}

\section{Appendix}
We have created a specific testing plan that involves a mix of automated and manual testing to cover functionality, performance, compatibility, and security. Tools like JUnit, Jest, Selenium, Cypress, JMeter, and BrowserStack will help us execute tests efficiently and ensure a high-quality game experience for players. Regularly re-running automated tests, especially after updates, will also support continuous improvement and stability.

\subsection{Testing Types and Tools}
\textbf{Unit Testing}
\begin{itemize}
    \item \textbf{Goal}: Test individual functions or methods (e.g., card drawing, shuffling, rule enforcement) to ensure correct outputs.
    \item \textbf{Tool}:
    \begin{itemize}
        \item Java: JUnit for automated unit testing.
        \item JavaScript: Jest for creating and running unit tests.
    \end{itemize}
\end{itemize}

\textbf{Integration Testing}
\begin{itemize}
    \item \textbf{Goal}: Ensure different game components (e.g., card management and scoring) work together seamlessly.
    \item \textbf{Tool}:
    \begin{itemize}
        \item Java: JUnit and Mockito to test the integration of different modules.
        \item JavaScript: Jest combined with Sinon.js for mocking dependencies.
    \end{itemize}
\end{itemize}

\textbf{System Testing}
\begin{itemize}
    \item \textbf{Goal}: Validate the entire game’s functionality, including game flow, player turns, and win/loss conditions.
    \item \textbf{Tool}: Selenium WebDriver for end-to-end testing, simulating user actions to verify complete functionality.
\end{itemize}

\textbf{User Interface (UI) Testing}
\begin{itemize}
    \item \textbf{Goal}: Test the user interface elements such as buttons, menus, and in-game animations for usability and responsiveness.
    \item \textbf{Tool}:
    \begin{itemize}
        \item JavaScript: Cypress or Puppeteer to automate UI tests and ensure elements behave as expected.
    \end{itemize}
\end{itemize}

\textbf{Performance Testing}
\begin{itemize}
    \item \textbf{Goal}: Evaluate game performance, including load times, memory usage, and responsiveness during peak usage.
    \item \textbf{Tool}:
    \begin{itemize}
        \item Java: Apache JMeter to simulate multiple users and test performance under load.
        \item JavaScript: Lighthouse or WebPageTest to analyze load speed and responsiveness.
    \end{itemize}
\end{itemize}

\textbf{Compatibility Testing}
\begin{itemize}
    \item \textbf{Goal}: Ensure the game runs smoothly across different browsers, devices, and screen resolutions.
    \item \textbf{Tool}: BrowserStack or Sauce Labs for cross-browser and cross-device testing.
\end{itemize}

\textbf{Regression Testing}
\begin{itemize}
    \item \textbf{Goal}: Verify that new updates or changes do not break existing functionality.
    \item \textbf{Tool}: Selenium WebDriver to automate key test cases and re-run them after each update.
\end{itemize}

\textbf{User Experience (UX) Testing}
\begin{itemize}
    \item \textbf{Goal}: Collect feedback on game flow, design, and enjoyment to enhance the player experience.
    \item \textbf{Tool}: Conduct manual playtesting sessions with real users and gather feedback via surveys or interviews.
\end{itemize}

\textbf{Security Testing}
\begin{itemize}
    \item \textbf{Goal}: Identify and mitigate potential security vulnerabilities, ensuring safe user data handling.
    \item \textbf{Tool}: OWASP ZAP for testing vulnerabilities such as data leaks or injection attacks.
\end{itemize}

\section*{Appendix --- Reflection}
The information in this section will be used to evaluate the team members on the graduate attribute of Lifelong Learning.

\begin{enumerate}
    \item \textbf{What went well while writing this deliverable?}
    \begin{itemize}
        \item Mingyang: We used a shared document platform during the writing process, which helped us achieve real-time collaboration. Each member can view and provide feedback on other members' work at any time. This transparent process allows us to discover and solve some minor problems in a timely manner, avoid duplication of work, and ensure the coherence between each part.
    \end{itemize}
    
    \item \textbf{What pain points did you experience during this deliverable, and how did you resolve them?}
    \begin{itemize}
        \item Mingyang: The main pain point was distinguishing between functional and non-functional requirements. By referring to feedback and additional readings, I clarified these distinctions and revised the requirements accordingly.
    \end{itemize}
    
    \item \textbf{What knowledge and skills will the team collectively need to acquire to successfully complete the verification and validation of your project?}
    \begin{itemize}
        \item Jianhao: Static testing for functional requirements and dynamic testing for non-functional requirements are essential. Additionally, skills in automated testing tools will be beneficial.
    \end{itemize}

    \item \textbf{For each of the knowledge areas and skills identified, what are at least two approaches to acquiring the knowledge or mastering the skill?}
    \begin{itemize}
        \item Jianhao: We can refer to course notes from prior software testing courses and seek online tutorials. Team members with experience in specific testing areas can assist others.
    \end{itemize}
\end{enumerate}

\end{document}





\end{document}